package com.backpackr

import org.apache.spark.sql.SparkSession

object HiveTableManager {

  /**
   * Hive External Table ìƒì„± í•¨ìˆ˜
   * @param externalPath ì €ì¥ëœ Parquet ì ˆëŒ€ê²½ë¡œ
   */
  def createExternalTable(externalPath: String)(implicit spark: SparkSession): Unit = {
    // í…Œì´ë¸”ì´ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‚­ì œ
    spark.sql("DROP TABLE IF EXISTS backpackr_events")

    spark.sql(
      s"""
         |CREATE EXTERNAL TABLE IF NOT EXISTS backpackr_events (
         |  event_time TIMESTAMP,
         |  event_type STRING,
         |  product_id INT,
         |  category_id BIGINT,
         |  category_code STRING,
         |  brand STRING,
         |  price DOUBLE,
         |  user_id INT,
         |  user_session STRING,
         |  event_time_kst TIMESTAMP,
         |  session_id STRING
         |)
         |PARTITIONED BY (partition_date STRING)
         |STORED AS PARQUET
         |LOCATION '$externalPath'
         |TBLPROPERTIES ('parquet.compression'='SNAPPY')
         |""".stripMargin)

    // MetaStore Check. íŒŒí‹°ì…˜ metadata ë™ê¸°í™”
    spark.sql("MSCK REPAIR TABLE backpackr_events")

    // ê²°ê³¼ í™•ì¸
    println("ğŸ“‹ Hive í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸:")
    spark.sql("SHOW TABLES").show(truncate = false)

    println("ğŸ“Š Hive í…Œì´ë¸” ë°ì´í„° ìˆ˜ (ë°±ì—”ë“œ ê¸°ì¤€):")
    spark.sql("SELECT COUNT(*) AS total FROM backpackr_events").show()
  }
}

